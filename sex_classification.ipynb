{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to end sex classification code - PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import logging\n",
    "import datetime\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset, random_split, Dataset\n",
    "from torch.utils.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.2\n",
    "TRAIN_RATIO = 1 - VAL_RATIO - TEST_RATIO\n",
    "DATA_PARALELL = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATASET = 'HCP'\n",
    "PHASE = 'TRAIN'\n",
    "K_FOLDS = 5\n",
    "\n",
    "TASK = 'classification'\n",
    "ROOT_DIR = '/data/ninad/fieldmaps/HCP_T1w'\n",
    "LABEL_DIR='/data/ninad/fieldmaps/HCPCN2mm.csv'\n",
    "LOG_DIR = '/home/neelamlab/ninad/DWI/logs'\n",
    "timestamp = datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')\n",
    "RESULT_DIR = f'/home/neelamlab/ninad/DWI/results/run_{timestamp}'\n",
    "os.makedirs(RESULT_DIR,exist_ok=True)\n",
    "TEST_BATCH_SIZE = 2\n",
    "\n",
    "BATCH_SIZE=16\n",
    "LEARNING_RATE=0.0001\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "\n",
    "NP_SEED = 42\n",
    "TORCH_SEED = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2ba03e9ab0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(NP_SEED)\n",
    "torch.manual_seed(TORCH_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(logs_dir=LOG_DIR,dataset=None,phase=None):\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "    logger = logging.getLogger('RunLogger')\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    if not logger.hasHandlers():\n",
    "        timestamp = datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S')\n",
    "        file_handler = logging.FileHandler(os.path.join(logs_dir, f'{phase}_{dataset}_{timestamp}.log'))\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "LOGGER = setup_logger(logs_dir=LOG_DIR,phase=PHASE,dataset=DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fieldmapdata(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for loading neuroimaging data and associated labels for classification or regression tasks.\n",
    "\n",
    "    Attributes:\n",
    "        root_dir (str): Path to the directory containing image data files (.nii or .nii.gz).\n",
    "        label_dir (str): Path to the CSV file containing labels for each subject.\n",
    "        task (str): Specifies the task type: classification (Gender) or regression (Age).\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, label_dir, task='classification'):\n",
    "        self.labels_df = self.load_labels(label_dir) #load the labels\n",
    "        self.samples = self.make_dataset(root_dir, task=task) #assign the labels to each file in the root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        nifti_data = nib.load(img_path)\n",
    "        data = nifti_data.get_fdata()\n",
    "        image_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0) #unsqueeze to add channel dimension\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "        return image_tensor, label_tensor\n",
    "       \n",
    "    def make_dataset(self, root_dir, task = None):\n",
    "        samples = []\n",
    "        labels_df = self.labels_df\n",
    "        for root, _, fnames in os.walk(root_dir):\n",
    "            for fname in fnames:\n",
    "                if fname.endswith(\".nii.gz\") or fname.endswith(\".nii\"):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    id_ = self.extract_id_from_filename(fname)\n",
    "                    try:\n",
    "                        if task == 'regression': \n",
    "                            label = labels_df[labels_df['Subject'] == id_]['Age'].iloc[0] \n",
    "                        if task == 'classification': \n",
    "                            label = labels_df[labels_df['Subject'] == id_]['Gender'].iloc[0]\n",
    "                        samples.append((path, label))\n",
    "                    except:\n",
    "                        continue\n",
    "        return samples\n",
    "    \n",
    "    def extract_id_from_filename(self, fname):\n",
    "        '''match the filename to key to query in the labels dictionary'''\n",
    "        fname = fname.replace(\"sub-\",\"\")\n",
    "        if fname.endswith(\"_ad.nii.gz\"):\n",
    "            id_ = fname.replace(\"_ad.nii.gz\", \"\")\n",
    "        elif fname.endswith(\"_rd.nii.gz\"):\n",
    "            id_ = fname.replace(\"_rd.nii.gz\", \"\")\n",
    "        elif fname.endswith(\"_adc.nii.gz\"):\n",
    "            id_ = fname.replace(\"_adc.nii.gz\", \"\")\n",
    "        elif fname.endswith(\"_fa.nii.gz\"):\n",
    "            id_ = fname.replace(\"_fa.nii.gz\", \"\")\n",
    "        elif fname.endswith(\".nii.gz\"):\n",
    "            id_ = fname.replace(\".nii.gz\", \"\")\n",
    "        return id_\n",
    "\n",
    "    def load_labels(self, label_path):\n",
    "        '''tip: use astype(required datatype)'''\n",
    "        df = pd.read_csv(label_path)\n",
    "        df_filtered = df[['Subject', 'Gender', 'Age']].copy()\n",
    "        df_filtered['Gender'] = df_filtered['Gender'].map({'M': 0, 'F': 1}).astype(int)\n",
    "        df_filtered['Age'] = df_filtered['Age'].apply(lambda x: (int(x.split('-')[0]) + int(x.split('-')[1])) // 2 if '-' in x else int(x[:-1])).astype(float)\n",
    "        # In HCP-Y age is a bin of 4 years, here i can assigning the average value of the bin range to each subject\n",
    "        df_filtered['Subject'] = df_filtered['Subject'].astype(str)\n",
    "        return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset and split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Fieldmapdata(root_dir=ROOT_DIR,label_dir=LABEL_DIR,task=TASK)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [TRAIN_RATIO, VAL_RATIO, TEST_RATIO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the shape of image at each stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw image shape (91, 109, 91) \n",
      "Train image shape torch.Size([1, 91, 109, 91]) \n",
      "Batch shape torch.Size([16, 1, 91, 109, 91])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_IMAGE_PATH = '/data/ninad/fieldmaps/HCP_T1w/sub-100610.nii.gz'\n",
    "raw_image = nib.load(RANDOM_IMAGE_PATH).get_fdata()\n",
    "train_image = train_dataset.__getitem__(1)[0]\n",
    "train_batch = next(iter(train_dl))\n",
    "\n",
    "print('Raw image shape',raw_image.shape,'\\n' 'Train image shape', train_image.shape,'\\n' 'Batch shape',train_batch[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify the labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split_classification(dataset, test_size):\n",
    "    labels = [dataset[i][-1] for i in range(len(dataset))]  # Assuming label is the last element\n",
    "    # cannot access sample variable for all instances, will thorw AttributeError: 'Subset' object has no attribute 'samples'\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        range(dataset.__len__()), test_size=test_size, stratify=labels\n",
    "    )\n",
    "    train_ds = Subset(dataset, train_indices)\n",
    "    test_ds = Subset(dataset, test_indices)\n",
    "    return train_ds, test_ds\n",
    "\n",
    "def splitting_data(dataset, TEST_RATIO: float, stratify: bool=False):\n",
    "    if stratify:\n",
    "        train_ds, test_ds = stratified_split_classification(dataset, TEST_RATIO)\n",
    "    else:\n",
    "        train_ds, test_ds = random_split(dataset, [1-TEST_RATIO, TEST_RATIO])\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val_ds, test_ds = stratified_split_classification(dataset, test_size=TEST_RATIO)\n",
    "train_ds, val_ds = stratified_split_classification(train_and_val_ds, test_size=VAL_RATIO)\n",
    "LOGGER.info('Data split completed !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase Train, total: 542, ratio: tensor([0.8007])\n",
      "Phase Val, total: 136, ratio: tensor([0.7895])\n",
      "Phase Test, total: 170, ratio: tensor([0.7895])\n"
     ]
    }
   ],
   "source": [
    "dataset_labels = []\n",
    "for ds in [train_ds, val_ds, test_ds]:\n",
    "    labels = []\n",
    "    for i, j in ds:\n",
    "        labels.append(j)\n",
    "    dataset_labels.append(labels)\n",
    "    \n",
    "for num, phase in enumerate(['Train', 'Val', 'Test']):\n",
    "    Total_subjects = len(dataset_labels[num]), \n",
    "    males_count = len(dataset_labels[num]) - sum(dataset_labels[num])\n",
    "    females_count = sum(dataset_labels[num]), \n",
    "    ratio = (len(dataset_labels[num]) - sum(dataset_labels[num])) / sum(dataset_labels[num])\n",
    "    print(f'Phase {phase}, total: {Total_subjects[0]}, ratio: {ratio}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My dataloder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(dataset: Dataset, batch_size: int, num_workers: int = 4):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size, # hyperparameter, 8 is good, (lower batch size fine grain details)\n",
    "        pin_memory=True, # proved to be faster while using DDP\n",
    "        shuffle=False, #shuffle is mutually exclusive with distributed sampler\n",
    "        num_workers=num_workers, # 4, CPUs used to deliver the data to GPU, higher value --> better GPU utilisation, does not guarrentee faster epoch\n",
    "        sampler=DistributedSampler(dataset) #required for DDP\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''copied from https://github.com/ha-ha-ha-han/UKBiobank_deep_pretrain/blob/master/dp_model/model_files/sfcn.py'''\n",
    "'''This code is hardcoded for a specific input shape: ie. [batch_size, 1, 160, 192, 160]'''\n",
    "\n",
    "class SFCN(nn.Module):\n",
    "    def __init__(self, channel_number=[32, 64, 128, 256, 256, 64], output_dim=1, dropout=True): #default output_dim changed from 40 to 1\n",
    "        super(SFCN, self).__init__()\n",
    "        n_layer = len(channel_number)\n",
    "        self.feature_extractor = nn.Sequential()\n",
    "        for i in range(n_layer):\n",
    "            if i == 0:\n",
    "                in_channel = 1\n",
    "            else:\n",
    "                in_channel = channel_number[i-1]\n",
    "            out_channel = channel_number[i]\n",
    "            if i < n_layer-1:\n",
    "                self.feature_extractor.add_module('conv_%d' % i,\n",
    "                                                  self.conv_layer(in_channel,\n",
    "                                                                  out_channel,\n",
    "                                                                  maxpool=True,\n",
    "                                                                  kernel_size=3,\n",
    "                                                                  padding=1))\n",
    "            else:\n",
    "                self.feature_extractor.add_module('conv_%d' % i,\n",
    "                                                  self.conv_layer(in_channel,\n",
    "                                                                  out_channel,\n",
    "                                                                  maxpool=False,\n",
    "                                                                  kernel_size=1,\n",
    "                                                                  padding=0))\n",
    "        self.classifier = nn.Sequential()\n",
    "        ############################## Hard coded ####################################### \n",
    "        #avg_shape = [5, 6, 5] \n",
    "        #self.classifier.add_module('average_pool', nn.AvgPool3d(avg_shape))\n",
    "        ############################## Hard coded ####################################### \n",
    "\n",
    "        ############################## Change ####################################### \n",
    "        self.classifier.add_module('average_pool', nn.AdaptiveAvgPool3d(1))\n",
    "        ############################## Change ####################################### \n",
    "\n",
    "        if dropout is True:\n",
    "            self.classifier.add_module('dropout', nn.Dropout(0.5))\n",
    "        i = n_layer\n",
    "        in_channel = channel_number[-1]\n",
    "        out_channel = output_dim\n",
    "        self.classifier.add_module('conv_%d' % i,\n",
    "                                   nn.Conv3d(in_channel, out_channel, padding=0, kernel_size=1))\n",
    "\n",
    "    @staticmethod\n",
    "    def conv_layer(in_channel, out_channel, maxpool=True, kernel_size=3, padding=0, maxpool_stride=2):\n",
    "        if maxpool is True:\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv3d(in_channel, out_channel, padding=padding, kernel_size=kernel_size),\n",
    "                nn.BatchNorm3d(out_channel),\n",
    "                nn.MaxPool3d(2, stride=maxpool_stride),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            layer = nn.Sequential(\n",
    "                nn.Conv3d(in_channel, out_channel, padding=padding, kernel_size=kernel_size),\n",
    "                nn.BatchNorm3d(out_channel),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        return layer\n",
    "\n",
    "    def forward_original (self, x):\n",
    "        out = list()\n",
    "        x_f = self.feature_extractor(x)\n",
    "        x = self.classifier(x_f)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        out.append(x)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''Instead of list output datatype i prefer tensor and as we are performing Binary classification / Regression, we will not apply softmax'''\n",
    "        # print('In shape', x.shape)\n",
    "        x_f = self.feature_extractor(x)\n",
    "        # print('After feature extraction module shape', x_f.shape)\n",
    "        x = self.classifier(x_f)\n",
    "        # print('After classification module shape', x.shape)\n",
    "        x = x.view(x.size(0), -1) #flattening\n",
    "        # print('After Flattening shape', x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SFCN                                     [16, 1]                   --\n",
       "├─Sequential: 1-1                        [16, 64, 2, 3, 2]         --\n",
       "│    └─Sequential: 2-1                   [16, 32, 45, 54, 45]      --\n",
       "│    │    └─Conv3d: 3-1                  [16, 32, 91, 109, 91]     896\n",
       "│    │    └─BatchNorm3d: 3-2             [16, 32, 91, 109, 91]     64\n",
       "│    │    └─MaxPool3d: 3-3               [16, 32, 45, 54, 45]      --\n",
       "│    │    └─ReLU: 3-4                    [16, 32, 45, 54, 45]      --\n",
       "│    └─Sequential: 2-2                   [16, 64, 22, 27, 22]      --\n",
       "│    │    └─Conv3d: 3-5                  [16, 64, 45, 54, 45]      55,360\n",
       "│    │    └─BatchNorm3d: 3-6             [16, 64, 45, 54, 45]      128\n",
       "│    │    └─MaxPool3d: 3-7               [16, 64, 22, 27, 22]      --\n",
       "│    │    └─ReLU: 3-8                    [16, 64, 22, 27, 22]      --\n",
       "│    └─Sequential: 2-3                   [16, 128, 11, 13, 11]     --\n",
       "│    │    └─Conv3d: 3-9                  [16, 128, 22, 27, 22]     221,312\n",
       "│    │    └─BatchNorm3d: 3-10            [16, 128, 22, 27, 22]     256\n",
       "│    │    └─MaxPool3d: 3-11              [16, 128, 11, 13, 11]     --\n",
       "│    │    └─ReLU: 3-12                   [16, 128, 11, 13, 11]     --\n",
       "│    └─Sequential: 2-4                   [16, 256, 5, 6, 5]        --\n",
       "│    │    └─Conv3d: 3-13                 [16, 256, 11, 13, 11]     884,992\n",
       "│    │    └─BatchNorm3d: 3-14            [16, 256, 11, 13, 11]     512\n",
       "│    │    └─MaxPool3d: 3-15              [16, 256, 5, 6, 5]        --\n",
       "│    │    └─ReLU: 3-16                   [16, 256, 5, 6, 5]        --\n",
       "│    └─Sequential: 2-5                   [16, 256, 2, 3, 2]        --\n",
       "│    │    └─Conv3d: 3-17                 [16, 256, 5, 6, 5]        1,769,728\n",
       "│    │    └─BatchNorm3d: 3-18            [16, 256, 5, 6, 5]        512\n",
       "│    │    └─MaxPool3d: 3-19              [16, 256, 2, 3, 2]        --\n",
       "│    │    └─ReLU: 3-20                   [16, 256, 2, 3, 2]        --\n",
       "│    └─Sequential: 2-6                   [16, 64, 2, 3, 2]         --\n",
       "│    │    └─Conv3d: 3-21                 [16, 64, 2, 3, 2]         16,448\n",
       "│    │    └─BatchNorm3d: 3-22            [16, 64, 2, 3, 2]         128\n",
       "│    │    └─ReLU: 3-23                   [16, 64, 2, 3, 2]         --\n",
       "├─Sequential: 1-2                        [16, 1, 1, 1, 1]          --\n",
       "│    └─AdaptiveAvgPool3d: 2-7            [16, 64, 1, 1, 1]         --\n",
       "│    └─Dropout: 2-8                      [16, 64, 1, 1, 1]         --\n",
       "│    └─Conv3d: 2-9                       [16, 1, 1, 1, 1]          65\n",
       "==========================================================================================\n",
       "Total params: 2,950,401\n",
       "Trainable params: 2,950,401\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 182.60\n",
       "==========================================================================================\n",
       "Input size (MB): 57.77\n",
       "Forward/backward pass size (MB): 9727.25\n",
       "Params size (MB): 11.80\n",
       "Estimated Total Size (MB): 9796.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = SFCN()\n",
    "summary(model=model, input_size=(16,1,91,109,91))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Optimiser, Loss etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SFCN().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "# criterion2 = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(1.28,dtype=torch.float32)) # Total subjects: 899 Number of males : 395, number of females: 504, pos_weight = 1.2759493670886075\n",
    "# Females are class 1, ratio of class to class 0 --> 504/395 = 1.27\n",
    "# if using cross entropy loss / BCEloss instead of BCEwothlogits loss remember to use sigmoid / softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simpler train/val loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: Train Loss: 1.2264 Train Accu: 66.01% Val Loss: 1.3759 Val Accu: 56.47%\n",
      "Epoch [2/10]: Train Loss: 0.9750 Train Accu: 80.94% Val Loss: 2.1438 Val Accu: 56.47%\n",
      "Epoch [3/10]: Train Loss: 0.7570 Train Accu: 89.78% Val Loss: 1.6919 Val Accu: 56.47%\n",
      "Epoch [4/10]: Train Loss: 0.6767 Train Accu: 92.73% Val Loss: 0.4865 Val Accu: 57.06%\n",
      "Epoch [5/10]: Train Loss: 0.5644 Train Accu: 95.48% Val Loss: 1.0497 Val Accu: 56.47%\n",
      "Epoch [6/10]: Train Loss: 0.4637 Train Accu: 98.82% Val Loss: 0.8312 Val Accu: 57.06%\n",
      "Epoch [7/10]: Train Loss: 0.3794 Train Accu: 99.61% Val Loss: 0.6105 Val Accu: 45.88%\n",
      "Epoch [8/10]: Train Loss: 0.3283 Train Accu: 100.00% Val Loss: 0.5350 Val Accu: 60.00%\n",
      "Epoch [9/10]: Train Loss: 0.2846 Train Accu: 100.00% Val Loss: 0.4364 Val Accu: 61.18%\n",
      "Epoch [10/10]: Train Loss: 0.2597 Train Accu: 100.00% Val Loss: 0.8957 Val Accu: 57.06%\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    for inputs, labels in train_dl:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        tloss = criterion(outputs, labels)\n",
    "        tloss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += tloss.item() / inputs.size(0)\n",
    "        probability = torch.sigmoid(outputs) # during inference you have to apply sigmoid\n",
    "        predicted = (probability >= 0.5).float()\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dl:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            vloss = criterion(outputs, labels)\n",
    "            val_loss += vloss.item() / inputs.size(0)\n",
    "            probability = torch.sigmoid(outputs)\n",
    "            predicted = (probability >= 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.2f}% Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.2f}%\")\n",
    "        LOGGER.info(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.4f} Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.4f}\")\n",
    "torch.save(model.state_dict(),'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SFCN()\n",
    "# best_model.load_state_dict('best_model.pt')\n",
    "\n",
    "#using the above model for now\n",
    "new_state_dict = {}\n",
    "for key, value in model.state_dict().items():\n",
    "    new_key = key.replace(\"module.\", \"\")\n",
    "    new_state_dict[new_key] = value\n",
    "best_model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS: 42.06333679519594, TEST ACCURACY: 55.62130177514793\n",
      "Accuracy: 0.5562130177514792, Sensitivity (Recall): 1.0\n",
      "CM:  [[ 1 75]\n",
      " [ 0 93]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIjCAYAAACTRapjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+X0lEQVR4nO3deVyU5f7/8feAMiAIuKKWAu4alpIec9ckrdRcMzML0BbLFkVbPKmJppSV2qq2uZW2nMzSFjVNzSTL3VxwT1PBLSRUwOD+/dHP+TahBsYw41yv53nM4yHX3HPfn5tz7Hx6X9d9jc2yLEsAAAAwho+7CwAAAEDxogEEAAAwDA0gAACAYWgAAQAADEMDCAAAYBgaQAAAAMPQAAIAABiGBhAAAMAwNIAAAACGoQEEcEm7du1Shw4dFBISIpvNpvnz5xfp+ffv3y+bzaYZM2YU6XmvZG3btlXbtm3dXQYAL0YDCFwB9uzZowceeEDVq1eXv7+/goOD1aJFC7388ss6e/asS68dGxurLVu2aNy4cZo9e7YaN27s0usVp7i4ONlsNgUHB1/w97hr1y7ZbDbZbDa9+OKLhT7/4cOHNXr0aG3cuLEIqgWAolPC3QUAuLQvvvhCt99+u+x2u+655x5FRUUpJydHq1at0uOPP66tW7fqzTffdMm1z549q+TkZD399NN6+OGHXXKN8PBwnT17ViVLlnTJ+f9JiRIldObMGS1YsEC9e/d2eu/999+Xv7+/srKyLuvchw8fVmJioiIiItSwYcMCf27x4sWXdT0AKCgaQMCD7du3T3369FF4eLiWLVumypUrO94bNGiQdu/erS+++MJl1z927JgkKTQ01GXXsNls8vf3d9n5/4ndbleLFi00d+7cfA3gnDlz1KlTJ33yySfFUsuZM2dUqlQp+fn5Fcv1AJiLKWDAg02YMEGZmZl65513nJq/82rWrKnHHnvM8fMff/yhsWPHqkaNGrLb7YqIiNB///tfZWdnO30uIiJCnTt31qpVq/Sf//xH/v7+ql69umbNmuU4ZvTo0QoPD5ckPf7447LZbIqIiJD059Tp+T//1ejRo2Wz2ZzGlixZopYtWyo0NFRBQUGqU6eO/vvf/zrev9gawGXLlqlVq1YKDAxUaGiounbtqu3bt1/wert371ZcXJxCQ0MVEhKi+Ph4nTlz5uK/2L/p27evvvrqK6WnpzvGfvrpJ+3atUt9+/bNd/zJkyc1bNgwNWjQQEFBQQoODtYtt9yiTZs2OY5Zvny5mjRpIkmKj493TCWfv8+2bdsqKipK69atU+vWrVWqVCnH7+XvawBjY2Pl7++f7/47duyoMmXK6PDhwwW+VwCQaAABj7ZgwQJVr15dzZs3L9Dx9957r0aNGqXo6GhNmjRJbdq0UVJSkvr06ZPv2N27d6tXr1666aab9NJLL6lMmTKKi4vT1q1bJUk9evTQpEmTJEl33nmnZs+ercmTJxeq/q1bt6pz587Kzs7WmDFj9NJLL+m2227T999/f8nPffPNN+rYsaOOHj2q0aNHKyEhQatXr1aLFi20f//+fMf37t1bv//+u5KSktS7d2/NmDFDiYmJBa6zR48estlsmjdvnmNszpw5qlu3rqKjo/Mdv3fvXs2fP1+dO3fWxIkT9fjjj2vLli1q06aNoxmrV6+exowZI0m6//77NXv2bM2ePVutW7d2nOfEiRO65ZZb1LBhQ02ePFnt2rW7YH0vv/yyKlSooNjYWOXm5kqSpk2bpsWLF+vVV19VlSpVCnyvACBJsgB4pFOnTlmSrK5duxbo+I0bN1qSrHvvvddpfNiwYZYka9myZY6x8PBwS5K1cuVKx9jRo0ctu91uDR061DG2b98+S5L1wgsvOJ0zNjbWCg8Pz1fDM888Y/31HyuTJk2yJFnHjh27aN3nrzF9+nTHWMOGDa2KFStaJ06ccIxt2rTJ8vHxse6555581+vfv7/TObt3726VK1fuotf8630EBgZalmVZvXr1stq3b29ZlmXl5uZalSpVshITEy/4O8jKyrJyc3Pz3YfdbrfGjBnjGPvpp5/y3dt5bdq0sSRZU6dOveB7bdq0cRpbtGiRJcl69tlnrb1791pBQUFWt27d/vEeAeBCSAABD5WRkSFJKl26dIGO//LLLyVJCQkJTuNDhw6VpHxrBevXr69WrVo5fq5QoYLq1KmjvXv3XnbNf3d+7eBnn32mvLy8An3myJEj2rhxo+Li4lS2bFnH+LXXXqubbrrJcZ9/NXDgQKefW7VqpRMnTjh+hwXRt29fLV++XKmpqVq2bJlSU1MvOP0r/blu0Mfnz3985ubm6sSJE47p7fXr1xf4mna7XfHx8QU6tkOHDnrggQc0ZswY9ejRQ/7+/po2bVqBrwUAf0UDCHio4OBgSdLvv/9eoON/+eUX+fj4qGbNmk7jlSpVUmhoqH755Ren8WrVquU7R5kyZfTbb79dZsX53XHHHWrRooXuvfdehYWFqU+fPvroo48u2Qyer7NOnTr53qtXr56OHz+u06dPO43//V7KlCkjSYW6l1tvvVWlS5fWhx9+qPfff19NmjTJ97s8Ly8vT5MmTVKtWrVkt9tVvnx5VahQQZs3b9apU6cKfM2rrrqqUA98vPjiiypbtqw2btyoV155RRUrVizwZwHgr2gAAQ8VHBysKlWq6Oeffy7U5/7+EMbF+Pr6XnDcsqzLvsb59WnnBQQEaOXKlfrmm2909913a/Pmzbrjjjt000035Tv23/g393Ke3W5Xjx49NHPmTH366acXTf8kafz48UpISFDr1q313nvvadGiRVqyZImuueaaAied0p+/n8LYsGGDjh49KknasmVLoT4LAH9FAwh4sM6dO2vPnj1KTk7+x2PDw8OVl5enXbt2OY2npaUpPT3d8URvUShTpozTE7Pn/T1llCQfHx+1b99eEydO1LZt2zRu3DgtW7ZM33777QXPfb7OlJSUfO/t2LFD5cuXV2Bg4L+7gYvo27evNmzYoN9///2CD86c97///U/t2rXTO++8oz59+qhDhw6KiYnJ9zspaDNeEKdPn1Z8fLzq16+v+++/XxMmTNBPP/1UZOcHYBYaQMCDPfHEEwoMDNS9996rtLS0fO/v2bNHL7/8sqQ/pzAl5XtSd+LEiZKkTp06FVldNWrU0KlTp7R582bH2JEjR/Tpp586HXfy5Ml8nz2/IfLft6Y5r3LlymrYsKFmzpzp1FD9/PPPWrx4seM+XaFdu3YaO3asXnvtNVWqVOmix/n6+uZLFz/++GMdOnTIaex8o3qhZrmwnnzySR04cEAzZ87UxIkTFRERodjY2Iv+HgHgUtgIGvBgNWrU0Jw5c3THHXeoXr16Tt8Esnr1an388ceKi4uTJF133XWKjY3Vm2++qfT0dLVp00Y//vijZs6cqW7dul10i5HL0adPHz355JPq3r27Hn30UZ05c0ZTpkxR7dq1nR6CGDNmjFauXKlOnTopPDxcR48e1RtvvKGrr75aLVu2vOj5X3jhBd1yyy1q1qyZBgwYoLNnz+rVV19VSEiIRo8eXWT38Xc+Pj4aMWLEPx7XuXNnjRkzRvHx8WrevLm2bNmi999/X9WrV3c6rkaNGgoNDdXUqVNVunRpBQYGqmnTpoqMjCxUXcuWLdMbb7yhZ555xrEtzfTp09W2bVuNHDlSEyZMKNT5AIBtYIArwM6dO6377rvPioiIsPz8/KzSpUtbLVq0sF599VUrKyvLcdy5c+esxMREKzIy0ipZsqRVtWpVa/jw4U7HWNaf28B06tQp33X+vv3IxbaBsSzLWrx4sRUVFWX5+flZderUsd57771828AsXbrU6tq1q1WlShXLz8/PqlKlinXnnXdaO3fuzHeNv2+V8s0331gtWrSwAgICrODgYKtLly7Wtm3bnI45f72/bzMzffp0S5K1b9++i/5OLct5G5iLudg2MEOHDrUqV65sBQQEWC1atLCSk5MvuH3LZ599ZtWvX98qUaKE0322adPGuuaaay54zb+eJyMjwwoPD7eio6Otc+fOOR03ZMgQy8fHx0pOTr7kPQDA39ksqxCrpAEAAHDFYw0gAACAYWgAAQAADEMDCAAAYBgaQAAAAMPQAAIAABiGBhAAAMAwNIAAAACG8cpvAjlzjq0NAW8VMfBjd5cAwEWOvtPbbdcOaPSwy859dsNrLjv35SIBBAAAMIxXJoAAAACFYjMrE6MBBAAAsNncXUGxMqvdBQAAAAkgAACAaVPAZt0tAAAASAABAABYAwgAAACvRgIIAADAGkAAAAB4MxJAAAAAw9YA0gACAAAwBQwAAABvRgIIAABg2BQwCSAAAIBhSAABAABYAwgAAABvRgIIAADAGkAAAAB4MxJAAAAAw9YA0gACAAAwBQwAAABvRgIIAABg2BSwWXcLAAAAEkAAAAASQAAAAHg1EkAAAAAfngIGAACAFyMBBAAAMGwNIA0gAAAAG0EDAADAm5EAAgAAGDYFbNbdAgAAgAQQAACANYAAAADwaiSAAAAArAEEAACANyMBBAAAMGwNIA0gAAAAU8AAAADwZiSAAAAAhk0BkwACAAAYhgQQAACANYAAAADwZiSAAAAArAEEAACANyMBBAAAMGwNIA0gAACAYQ2gWXcLAAAAEkAAAAAeAgEAAIBXIwEEAABgDSAAAAC8GQkgAAAAawABAADgzUgAAQAADFsDSAMIAADAFDAAAAC8GQkgAAAwno0EEAAAAO6Qm5urkSNHKjIyUgEBAapRo4bGjh0ry7Icx1iWpVGjRqly5coKCAhQTEyMdu3aVajr0AACAADj2Ww2l70K4/nnn9eUKVP02muvafv27Xr++ec1YcIEvfrqq45jJkyYoFdeeUVTp07VmjVrFBgYqI4dOyorK6vA12EKGAAAwEOsXr1aXbt2VadOnSRJERERmjt3rn788UdJf6Z/kydP1ogRI9S1a1dJ0qxZsxQWFqb58+erT58+BboOCSAAAIDNda/s7GxlZGQ4vbKzsy9YRvPmzbV06VLt3LlTkrRp0yatWrVKt9xyiyRp3759Sk1NVUxMjOMzISEhatq0qZKTkwt8uzSAAAAALpSUlKSQkBCnV1JS0gWPfeqpp9SnTx/VrVtXJUuWVKNGjTR48GDdddddkqTU1FRJUlhYmNPnwsLCHO8VBFPAAADAeK58Cnj48OFKSEhwGrPb7Rc89qOPPtL777+vOXPm6JprrtHGjRs1ePBgValSRbGxsUVWEw0gAAAwnisbQLvdftGG7+8ef/xxRwooSQ0aNNAvv/yipKQkxcbGqlKlSpKktLQ0Va5c2fG5tLQ0NWzYsMA1MQUMAADgIc6cOSMfH+f2zNfXV3l5eZKkyMhIVapUSUuXLnW8n5GRoTVr1qhZs2YFvg4JIAAAMJ6nbATdpUsXjRs3TtWqVdM111yjDRs2aOLEierfv7+kP+scPHiwnn32WdWqVUuRkZEaOXKkqlSpom7duhX4OjSAAAAAHuLVV1/VyJEj9dBDD+no0aOqUqWKHnjgAY0aNcpxzBNPPKHTp0/r/vvvV3p6ulq2bKmvv/5a/v7+Bb6Ozfrr1tJe4sw5r7slAP9fxMCP3V0CABc5+k5vt1075M7ZLjv3qbl3u+zcl4s1gAAAAIZhChgAAMAzlgAWGxJAAAAAw5AAAgAA43nKU8DFhQQQAADAMCSAAADAeKYlgDSAAADAeKY1gEwBAwAAGIYEEAAAGI8EEAAAAF6NBBAAAMCsAJAEEAAAwDQkgAAAwHisAQQAAIBXIwEEAADGMy0BpAEEAADGM60BZAoYAADAMCSAAAAAZgWAJIAAAACmIQEEAADGYw0gAAAAvBoJIAAAMB4JIAAAALwaCSAAADCeaQkgDSAAADCeaQ0gU8AAAACGIQEEAAAwKwAkAQQAADANCSAAADAeawABAADg1UgAAQCA8UgA3Wj37t1atGiRzp49K0myLMvNFQEAAHgfj2gAT5w4oZiYGNWuXVu33nqrjhw5IkkaMGCAhg4d6ubqAACAt7PZbC57eSKPaACHDBmiEiVK6MCBAypVqpRj/I477tDXX3/txsoAAIARbC58eSCPWAO4ePFiLVq0SFdffbXTeK1atfTLL7+4qSoAAADv5BEN4OnTp52Sv/NOnjwpu93uhooAAIBJPHWq1lU8Ygq4VatWmjVrluNnm82mvLw8TZgwQe3atXNjZQAAAN7HIxLACRMmqH379lq7dq1ycnL0xBNPaOvWrTp58qS+//57d5cHAAC8HAmgG0RFRWnnzp1q2bKlunbtqtOnT6tHjx7asGGDatSo4e7yAAAAvIpHJICSFBISoqefftrdZeAKsW7tT5o1/R1t27ZVx48d08SXX1O79jHuLgvAZVj7fCdVKx+Yb/zdZbv11Pvr9enjbdWibkWn92Yu36PHZ68rrhJhANMSQLc1gJs3by7wsddee60LK8GV6OzZs6pdp666du+poYMfcXc5AP6FjmO/ka/P//2fb92rgvW/YW31+dqDjrFZK/Zowvytjp/P5PxRrDUC3sZtDWDDhg1ls9n+8ds+bDabcnNzi6kqXClatmqtlq1au7sMAEXgRGa208+P3FpX+9J+1+qUY46xszm5OpqRVdylwSAkgMVk37597ro0AMBDlfT1Ua8bwjV18U6n8Z43VFOvG8J1NCNLizce1sSF23Q2h3AARcis/s99DWB4eHiRnCc7O1vZ2c7/9pjr48f+gQBwBbqlURWFlCqpD1b/X0gwb80B/XritFLTs1T/6hCN7HWtalYqrfg3VruxUuDK5jEPgUjStm3bdODAAeXk5DiN33bbbRf9TFJSkhITE53G/jtilJ4eNdoVJQIAXOiuVtW1dEuq0tL/b7p39sq9jj9vP3RKaaeyNO/xtoqoEKj9x067o0x4IaaA3WDv3r3q3r27tmzZ4rQu8Px/GZdaAzh8+HAlJCQ4jeX6+LmuWACAS1xdrpRa16+o+Ncvneyt33tCkhRZMYgGELhMHrEP4GOPPabIyEgdPXpUpUqV0tatW7Vy5Uo1btxYy5cvv+Rn7Xa7goODnV5M/wLAlefOFpE6npGtJZuPXPK4qGqhkqS0UzwUgqJjs9lc9vJEHpEAJicna9myZSpfvrx8fHzk4+Ojli1bKikpSY8++qg2bNjg7hLhYc6cOa2DBw44fj506Fel7Niu4JAQVa5cxY2VAbgcNpvUp2WEPly9X7l5/7c7RESFQPVoGq5vthzRb5nZqn91qMb2aajVKUe17ddTbqwYuLJ5RAOYm5ur0qVLS5LKly+vw4cPq06dOgoPD1dKSoqbq4Mn2vbzz7qvf6zj55cmPCdJ6tK1m8aMe85dZQG4TG3qh6lquUDNWeW8Q0TOH3lqXb+i7r+plkrZS+jwyTNauO5XTVy4zU2Vwlt5aFDnMh7RAEZFRWnTpk2KjIxU06ZNNWHCBPn5+enNN99U9erV3V0ePFDj/zTVhp93uLsMAEVk+dY0VRzwUb7xw7+dVbcJy4u/IMDLeUQDOGLECJ0+/edC3sTERHXp0kWtWrVSuXLl9MEHH7i5OgAA4O08da2eq3hEA9ixY0fHn2vVqqUdO3bo5MmTKlOmjHH/hQAAgOJnWrvh1gawf//+BTru3XffdXElAAAA5nBrAzhjxgyFh4erUaNG//idwAAAAK5i2oyjWxvABx98UHPnztW+ffsUHx+vfv36qWzZsu4sCQAAwOu5dSPo119/XUeOHNETTzyhBQsWqGrVqurdu7cWLVpEIggAAIqNzea6lydy+zeB2O123XnnnVqyZIm2bduma665Rg899JAiIiKUmZnp7vIAAAC8jkc8BXyej4+P47uAL/X9vwAAAEXJx8dDozoXcXsCmJ2drblz5+qmm25S7dq1tWXLFr322ms6cOCAgoKC3F0eAACA13FrAvjQQw/pgw8+UNWqVdW/f3/NnTtX5cuXd2dJAADAQJ66Vs9V3NoATp06VdWqVVP16tW1YsUKrVix4oLHzZs3r5grAwAAJmEbmGJ0zz33GPcLBwAAcDe3bwQNAADgbqblUW5/CAQAAADFy6O2gQEAAHAH05akkQACAAAYhgQQAAAYjwQQAAAAXo0EEAAAGM+wAJAGEAAAgClgAAAAeDUSQAAAYDzDAkASQAAAANOQAAIAAOOxBhAAAABejQQQAAAYz7AAkAQQAADANCSAAADAeKwBBAAAgFcjAQQAAMYzLACkAQQAAGAKGAAAAF6NBBAAABjPsACQBBAAAMA0JIAAAMB4rAEEAACAVyMBBAAAxjMsACQBBAAAMA0JIAAAMB5rAAEAAAxjs7nuVViHDh1Sv379VK5cOQUEBKhBgwZau3at433LsjRq1ChVrlxZAQEBiomJ0a5duwp1DRpAAAAAD/Hbb7+pRYsWKlmypL766itt27ZNL730ksqUKeM4ZsKECXrllVc0depUrVmzRoGBgerYsaOysrIKfB2mgAEAgPE8ZQr4+eefV9WqVTV9+nTHWGRkpOPPlmVp8uTJGjFihLp27SpJmjVrlsLCwjR//nz16dOnQNchAQQAAHCh7OxsZWRkOL2ys7MveOznn3+uxo0b6/bbb1fFihXVqFEjvfXWW4739+3bp9TUVMXExDjGQkJC1LRpUyUnJxe4JhpAAABgPJvN5rJXUlKSQkJCnF5JSUkXrGPv3r2aMmWKatWqpUWLFunBBx/Uo48+qpkzZ0qSUlNTJUlhYWFOnwsLC3O8VxBMAQMAALjQ8OHDlZCQ4DRmt9sveGxeXp4aN26s8ePHS5IaNWqkn3/+WVOnTlVsbGyR1UQCCAAAjOfKp4DtdruCg4OdXhdrACtXrqz69es7jdWrV08HDhyQJFWqVEmSlJaW5nRMWlqa472CoAEEAADwEC1atFBKSorT2M6dOxUeHi7pzwdCKlWqpKVLlzrez8jI0Jo1a9SsWbMCX4cpYAAAYDxPeQp4yJAhat68ucaPH6/evXvrxx9/1Jtvvqk333xT0p91Dh48WM8++6xq1aqlyMhIjRw5UlWqVFG3bt0KfB0aQAAAYDwP6f/UpEkTffrppxo+fLjGjBmjyMhITZ48WXfddZfjmCeeeEKnT5/W/fffr/T0dLVs2VJff/21/P39C3wdm2VZlituwJ3OnPO6WwLw/0UM/NjdJQBwkaPv9Hbbtdu9vNpl5/72seYuO/flIgEEAADG85Qp4OLCQyAAAACGIQEEAADGMywAJAEEAAAwDQkgAAAwno9hESAJIAAAgGFIAAEAgPEMCwBpAAEAANgGBgAAAF6NBBAAABjPx6wAkAQQAADANCSAAADAeKwBBAAAgFcjAQQAAMYzLAAkAQQAADANCSAAADCeTWZFgDSAAADAeGwDAwAAAK9GAggAAIzHNjAAAADwaiSAAADAeIYFgCSAAAAApiEBBAAAxvMxLAIkAQQAADAMCSAAADCeYQEgDSAAAADbwAAAAMCrkQACAADjGRYAkgACAACYhgQQAAAYj21gAAAA4NVIAAEAgPHMyv9IAAEAAIxDAggAAIxn2j6ANIAAAMB4Pmb1f0wBAwAAmIYEEAAAGM+0KWASQAAAAMOQAAIAAOMZFgCSAAIAAJiGBBAAABiPNYAAAADwaiSAAADAeKbtA0gDCAAAjMcUMAAAALwaCSAAADCeWfkfCSAAAIBxLqsB/O6779SvXz81a9ZMhw4dkiTNnj1bq1atKtLiAAAAioOPzeaylycqdAP4ySefqGPHjgoICNCGDRuUnZ0tSTp16pTGjx9f5AUCAACgaBW6AXz22Wc1depUvfXWWypZsqRjvEWLFlq/fn2RFgcAAFAcbDbXvTxRoRvAlJQUtW7dOt94SEiI0tPTi6ImAAAAuFChG8BKlSpp9+7d+cZXrVql6tWrF0lRAAAAxclms7ns5YkK3QDed999euyxx7RmzRrZbDYdPnxY77//voYNG6YHH3zQFTUCAACgCBV6H8CnnnpKeXl5at++vc6cOaPWrVvLbrdr2LBheuSRR1xRIwAAgEt5aFDnMoVuAG02m55++mk9/vjj2r17tzIzM1W/fn0FBQW5oj4AAACX89TtWlzlsr8JxM/PT/Xr1y/KWgAAAFAMCt0AtmvX7pILGpctW/avCgIAAChuhgWAhW8AGzZs6PTzuXPntHHjRv3888+KjY0tqroAAADgIoVuACdNmnTB8dGjRyszM/NfFwQAAFDcPHW7Fle5rO8CvpB+/frp3XffLarTAQAAwEUu+yGQv0tOTpa/v39Rne5fMe1JHsAkv69f6e4SALhMb7dducgSsStEoRvAHj16OP1sWZaOHDmitWvXauTIkUVWGAAAAFyj0A1gSEiI088+Pj6qU6eOxowZow4dOhRZYQAAAMXFtDWAhWoAc3NzFR8frwYNGqhMmTKuqgkAAKBY+ZjV/xVuytvX11cdOnRQenq6i8oBAACAqxV6zWNUVJT27t3riloAAADcwsfmupcnKnQD+Oyzz2rYsGFauHChjhw5ooyMDKcXAAAAPFuB1wCOGTNGQ4cO1a233ipJuu2225wWTFqWJZvNptzc3KKvEgAAwIV4COQiEhMTNXDgQH377beurAcAAAAuVuAG0LIsSVKbNm1cVgwAAIA7eOpaPVcp1BpA0+JRAAAAb1SofQBr1679j03gyZMn/1VBAAAAxc20jKtQDWBiYmK+bwIBAAC40vkY1gEWqgHs06ePKlas6KpaAAAAUAwK3ACy/g8AAHirQm+MfIUr8P2efwoYAAAAV7YCJ4B5eXmurAMAAMBtTJvoNC3xBAAAMF6hHgIBAADwRqY9BUwCCAAAYBgSQAAAYDzDAkAaQAAAAL4LGAAAAF6NBBAAABiPh0AAAADg1UgAAQCA8QwLAEkAAQAATEMCCAAAjMdTwAAAAPAIzz33nGw2mwYPHuwYy8rK0qBBg1SuXDkFBQWpZ8+eSktLK9R5aQABAIDxbC78z+X66aefNG3aNF177bVO40OGDNGCBQv08ccfa8WKFTp8+LB69OhRqHPTAAIAAOP52Fz3uhyZmZm666679NZbb6lMmTKO8VOnTumdd97RxIkTdeONN+r666/X9OnTtXr1av3www8Fv9/LKwsAAAAFkZ2drYyMDKdXdnb2JT8zaNAgderUSTExMU7j69at07lz55zG69atq2rVqik5ObnANdEAAgAA47kyAUxKSlJISIjTKykp6aK1fPDBB1q/fv0Fj0lNTZWfn59CQ0OdxsPCwpSamlrg++UpYAAAABcaPny4EhISnMbsdvsFjz148KAee+wxLVmyRP7+/i6riQYQAAAYz+bCnaDtdvtFG76/W7dunY4eParo6GjHWG5urlauXKnXXntNixYtUk5OjtLT051SwLS0NFWqVKnANdEAAgAAeIj27dtry5YtTmPx8fGqW7eunnzySVWtWlUlS5bU0qVL1bNnT0lSSkqKDhw4oGbNmhX4OjSAAADAeJ6yEXTp0qUVFRXlNBYYGKhy5co5xgcMGKCEhASVLVtWwcHBeuSRR9SsWTPdcMMNBb4ODSAAAMAVZNKkSfLx8VHPnj2VnZ2tjh076o033ijUOWyWZVkuqs9tsv5wdwUAXKVMk4fdXQIAFzm74TW3XXviyr0uO3dC6+ouO/flIgEEAADG83HhQyCeiH0AAQAADEMCCAAAjOcpD4EUFxJAAAAAw5AAAgAA4xm2BJAEEAAAwDQkgAAAwHg+MisCJAEEAAAwDAkgAAAwnmlrAGkAAQCA8dgGBgAAAF6NBBAAABiPr4IDAACAVyMBBAAAxjMsACQBBAAAMA0JIAAAMB5rAAEAAODVSAABAIDxDAsAaQABAABMmxI17X4BAACMRwIIAACMZzNsDpgEEAAAwDAkgAAAwHhm5X8kgAAAAMYhAQQAAMZjI2gAAAB4NRJAAABgPLPyPxpAAAAA474JhClgAAAAw5AAAgAA47ERNAAAALwaCSAAADCeaYmYafcLAABgPBJAAABgPNYAAgAAwKuRAAIAAOOZlf+RAAIAABiHBBAAABjPtDWANIAAAMB4pk2Jmna/AAAAxiMBBAAAxjNtCpgEEAAAwDAkgAAAwHhm5X8kgAAAAMYhAQQAAMYzbAkgCSAAAIBpSAABAIDxfAxbBUgDCAAAjMcUMAAAALwaCSAAADCezbApYBJAAAAAw5AAAgAA47EGEAAAAF6NBBAAABjPtG1gSAABAAAM4zENYHp6ut5++20NHz5cJ0+elCStX79ehw4dcnNlAADA29lsrnt5Io+YAt68ebNiYmIUEhKi/fv367777lPZsmU1b948HThwQLNmzXJ3iQAAwIt5aqPmKh6RACYkJCguLk67du2Sv7+/Y/zWW2/VypUr3VgZAACA9/GIBPCnn37StGnT8o1fddVVSk1NdUNFAADAJGwE7QZ2u10ZGRn5xnfu3KkKFSq4oSIAAADv5REN4G233aYxY8bo3LlzkiSbzaYDBw7oySefVM+ePd1cHQAA8HY+Nte9PJFHNIAvvfSSMjMzVbFiRZ09e1Zt2rRRzZo1Vbp0aY0bN87d5QEAAHgVj1gDGBISoiVLlmjVqlXavHmzMjMzFR0drZiYGHeXBgAADGDaGkCPaADPa9mypVq2bOnuMgAAALya2xrAV155pcDHPvrooy6sBAAAmM60fQDd1gBOmjSpQMfZbDYaQAAA4FJMAReTffv2uevSAAAARvOoNYAAAADu4KnbtbiKxzSAv/76qz7//HMdOHBAOTk5Tu9NnDjRTVUBAAB4H49oAJcuXarbbrtN1atX144dOxQVFaX9+/fLsixFR0e7uzwAAODlTFsD6BEbQQ8fPlzDhg3Tli1b5O/vr08++UQHDx5UmzZtdPvtt7u7PAAAAK/iEQ3g9u3bdc8990iSSpQoobNnzyooKEhjxozR888/7+bq4Mk+mPO+brnpRjVp1EB39bldWzZvdndJAAopqJRdLwzrqZQvx+hk8kR9OyNB19ev5nj/6Qdu1cZ5I3R89Us6vGKCvpj6sJpEhbuxYngjm811L0/kEQ1gYGCgY91f5cqVtWfPHsd7x48fd1dZ8HBff/WlXpyQpAceGqQPPv5UderU1YMPDNCJEyfcXRqAQpgyqq9uvKGu+o+Yqca9x+ub5B36YuojqlIhRJK0+5ejGvL8x2p8+3i1j5+oXw6f1II3Hlb5MkFurhy4cnlEA3jDDTdo1apVkqRbb71VQ4cO1bhx49S/f3/dcMMNbq4Onmr2zOnq0au3unXvqRo1a2rEM4ny9/fX/HmfuLs0AAXkby+pbu0b6unJ8/X9+j3ae/C4xk37UnsOHtN9t7eSJH349Vp9uyZF+w+d0Pa9qXrypXkKKR2gqFpV3Fw9vInNhS9P5BEPgUycOFGZmZmSpMTERGVmZurDDz9UrVq1eAIYF3QuJ0fbt23VgPsecIz5+Pjohhuaa/OmDW6sDEBhlPD1UYkSvsrKOec0npV9Ts0b1ch3fMkSvhrQo4XSfz+jLTsPFVeZMICPp87VuohHNIDVq1d3/DkwMFBTp04t8Gezs7OVnZ3tNGb52mW324usPnie39J/U25ursqVK+c0Xq5cOe3bt9dNVQEorMwz2fph014Nv+8WpexLU9qJDPW+ubGaXhupPQePOY67pVWUZj0Xr1L+JZV6PEOdB76mE+mn3Vg5cGXziCngv8rMzFRGRobT61KSkpIUEhLi9Hrh+aRiqhYA8G/1HzFLNpu0d/E4nVozWYPubKOPvl6rvDzLccyKn3aqaZ8ktYubqMWrt+m9Cf1VgTWAKEJMAbvBvn379PDDD2v58uXKyspyjFuWJZvNptzc3It+dvjw4UpISHAas3xJ/7xdmdAy8vX1zffAx4kTJ1S+fHk3VQXgcuz79bg63PuySvn7KTjIX6nHMzT7uXjtO/R/DwGeycrR3oPHtffgcf24Zb+2fDZKsd2b68V3F7uxcuDK5RENYL9+/WRZlt59912FhYXJVoh5eLs9/3Rv1h9FXSE8TUk/P9Wrf43W/JCsG9vHSJLy8vK0Zk2y+tzZz83VAbgcZ7JydCYrR6GlAxTTvJ6envzZRY/1sdlkL+kR/xcGb+GpUZ2LeMTfnk2bNmndunWqU6eOu0vBFeTu2HiN/O+TuuaaKEU1uFbvzZ6ps2fPqlv3Hu4uDUAhxDSrJ5tN2rn/qGpUraDxQ7pp5740zfo8WaX8/fTkvR31xYotSj1+SuVCg/RA79aqUjFU85asd3fpwBXLIxrAJk2a6ODBgzSAKJSbb7lVv508qTdee0XHjx9Tnbr19Ma0t1WOKWDgihIS5K8xj9ymq8JCdfLUGX22dKOeeX2B/vgjT74+eaoTEaZ+XZqqXGigTp46o7Vbf1FM/0navjfV3aXDi5j2VXA2y7Ksfz7Mtfbs2aOBAweqX79+ioqKUsmSJZ3ev/baawt1PqaAAe9VpsnD7i4BgIuc3fCa2669Zs8pl527aY0Ql537cnlEAnjs2DHt2bNH8fHxjjGbzVagh0AAAAD+LcO2AfSMBrB///5q1KiR5s6dW+iHQAAAAP4t0zoPj2gAf/nlF33++eeqWbOmu0sBAADweh6xEfSNN96oTZs2ubsMAABgKsN2gvaIBLBLly4aMmSItmzZogYNGuR7COS2225zU2UAAADexyOeAvbxuXgQeTkPgfAUMOC9eAoY8F7ufAp47b5Lf/Xsv9E4Mthl575cHjEFnJeXd9EXTwADAABTJCUlqUmTJipdurQqVqyobt26KSUlxemYrKwsDRo0SOXKlVNQUJB69uyptLS0Ql3HIxrAv/rrdwEDAAAUB5vNda/CWLFihQYNGqQffvhBS5Ys0blz59ShQwedPn3accyQIUO0YMECffzxx1qxYoUOHz6sHj0K9y1YHjEFnJubq/Hjx2vq1KlKS0vTzp07Vb16dY0cOVIREREaMGBAoc7HFDDgvZgCBryXO6eA1+133RTw9RGXPwV87NgxVaxYUStWrFDr1q116tQpVahQQXPmzFGvXr0kSTt27FC9evWUnJysG264oUDn9YgEcNy4cZoxY4YmTJggPz8/x3hUVJTefvttN1YGAABM4MqHgLOzs5WRkeH0ys7OLlBdp079+Q0lZcuWlSStW7dO586dU0xMjOOYunXrqlq1akpOTi7w/XpEAzhr1iy9+eabuuuuu+Tr6+sYv+6667Rjxw43VgYAAIzgwg4wKSlJISEhTq+kpKR/LCkvL0+DBw9WixYtFBUVJUlKTU2Vn5+fQkNDnY4NCwtTamrBvx/bI7aBOXTo0AU3gc7Ly9O5c+fcUBEAAEDRGD58uBISEpzG7Hb7P35u0KBB+vnnn7Vq1aoir8kjGsD69evru+++U3h4uNP4//73PzVq1MhNVQEAAFPYXLhjs91uL1DD91cPP/ywFi5cqJUrV+rqq692jFeqVEk5OTlKT093SgHT0tJUqVKlAp/fIxrAUaNGKTY2VocOHVJeXp7mzZunlJQUzZo1SwsXLnR3eQAAAMXCsiw98sgj+vTTT7V8+XJFRkY6vX/99derZMmSWrp0qXr27ClJSklJ0YEDB9SsWbMCX8etDeDevXsVGRmprl27asGCBRozZowCAwM1atQoRUdHa8GCBbrpppvcWSIAADBAYbdrcZVBgwZpzpw5+uyzz1S6dGnHur6QkBAFBAQoJCREAwYMUEJCgsqWLavg4GA98sgjatasWYGfAJbc3ADWqlVLR44cUcWKFdWqVSuVLVtWW7ZsUVhYmDvLAgAAcIspU6ZIktq2bes0Pn36dMXFxUmSJk2aJB8fH/Xs2VPZ2dnq2LGj3njjjUJdx60N4N+3IPzqq6+cNjoEAAAoDh4SAObrjS7E399fr7/+ul5//fXLvo5HbANzngfsSQ0AAOD13JoA2mw22f426f73nwEAAFzOsPbD7VPAcXFxjkejs7KyNHDgQAUGBjodN2/ePHeUBwAADOHKbWA8kVsbwNjYWKef+/Xr56ZKAAAAzOHWBnD69OnuvDwAAIAkz9kGprh41EMgAAAAcD2P+CYQAAAAdzIsACQBBAAAMA0JIAAAgGERIAkgAACAYUgAAQCA8UzbB5AEEAAAwDAkgAAAwHim7QNIAwgAAIxnWP/HFDAAAIBpSAABAAAMiwBJAAEAAAxDAggAAIzHNjAAAADwaiSAAADAeKZtA0MCCAAAYBgSQAAAYDzDAkAaQAAAANM6QKaAAQAADEMCCAAAjMc2MAAAAPBqJIAAAMB4bAMDAAAAr0YCCAAAjGdYAEgCCAAAYBoSQAAAAMMiQBpAAABgPLaBAQAAgFcjAQQAAMZjGxgAAAB4NRJAAABgPMMCQBJAAAAA05AAAgAAGBYBkgACAAAYhgQQAAAYz7R9AGkAAQCA8dgGBgAAAF6NBBAAABjPsACQBBAAAMA0JIAAAMB4rAEEAACAVyMBBAAAMGwVIAkgAACAYUgAAQCA8UxbA0gDCAAAjGdY/8cUMAAAgGlIAAEAgPFMmwImAQQAADAMCSAAADCezbBVgCSAAAAAhiEBBAAAMCsAJAEEAAAwDQkgAAAwnmEBIA0gAAAA28AAAADAq5EAAgAA47ENDAAAALwaCSAAAIBZASAJIAAAgGlIAAEAgPEMCwBJAAEAAExDAggAAIxn2j6ANIAAAMB4bAMDAAAAr0YCCAAAjGfaFDAJIAAAgGFoAAEAAAxDAwgAAGAY1gACAADjsQYQAAAAXo0EEAAAGM+0fQBpAAEAgPGYAgYAAIBXIwEEAADGMywAJAEEAAAwDQkgAACAYREgCSAAAIBhSAABAIDxTNsGhgQQAADAMCSAAADAeOwDCAAAAK9GAggAAIxnWABIAwgAAGBaB8gUMAAAgGFoAAEAgPFsLvzP5Xj99dcVEREhf39/NW3aVD/++GOR3i8NIAAAgAf58MMPlZCQoGeeeUbr16/Xddddp44dO+ro0aNFdg0aQAAAYDybzXWvwpo4caLuu+8+xcfHq379+po6dapKlSqld999t8julwYQAADAhbKzs5WRkeH0ys7OvuCxOTk5WrdunWJiYhxjPj4+iomJUXJycpHV5JVPAft75V3hQrKzs5WUlKThw4fLbre7uxwUg7MbXnN3CSgm/P1GcXJl7zD62SQlJiY6jT3zzDMaPXp0vmOPHz+u3NxchYWFOY2HhYVpx44dRVaTzbIsq8jOBhSzjIwMhYSE6NSpUwoODnZ3OQCKEH+/4S2ys7PzJX52u/2C/2Jz+PBhXXXVVVq9erWaNWvmGH/iiSe0YsUKrVmzpkhqIisDAABwoYs1exdSvnx5+fr6Ki0tzWk8LS1NlSpVKrKaWAMIAADgIfz8/HT99ddr6dKljrG8vDwtXbrUKRH8t0gAAQAAPEhCQoJiY2PVuHFj/ec//9HkyZN1+vRpxcfHF9k1aABxRbPb7XrmmWdYIA54If5+w1R33HGHjh07plGjRik1NVUNGzbU119/ne/BkH+Dh0AAAAAMwxpAAAAAw9AAAgAAGIYGEAAAwDA0gPA6+/fvl81m08aNG91dCgA3iYiI0OTJk91dBuCxaADhEeLi4mSz2TRw4MB87w0aNEg2m01xcXHFXxiAf3T+7+/fX7t373Z3aQAuggYQHqNq1ar64IMPdPbsWcdYVlaW5syZo2rVqrmxMgD/5Oabb9aRI0ecXpGRke4uC8BF0ADCY0RHR6tq1aqaN2+eY2zevHmqVq2aGjVq5Bj7+uuv1bJlS4WGhqpcuXLq3Lmz9uzZc8lz//zzz7rlllsUFBSksLAw3X333Tp+/LjL7gUwjd1uV6VKlZxevr6++uyzzxQdHS1/f39Vr15diYmJ+uOPPxyfs9lsmjZtmjp37qxSpUqpXr16Sk5O1u7du9W2bVsFBgaqefPmTn/H9+zZo65duyosLExBQUFq0qSJvvnmm0vWl56ernvvvVcVKlRQcHCwbrzxRm3atMllvw/A09EAwqP0799f06dPd/z87rvv5tv5/PTp00pISNDatWu1dOlS+fj4qHv37srLy7vgOdPT03XjjTeqUaNGWrt2rb7++mulpaWpd+/eLr0XwHTfffed7rnnHj322GPatm2bpk2bphkzZmjcuHFOx40dO1b33HOPNm7cqLp166pv37564IEHNHz4cK1du1aWZenhhx92HJ+Zmalbb71VS5cu1YYNG3TzzTerS5cuOnDgwEVruf3223X06FF99dVXWrdunaKjo9W+fXudPHnSZfcPeDQL8ACxsbFW165draNHj1p2u93av3+/tX//fsvf3986duyY1bVrVys2NvaCnz127JglydqyZYtlWZa1b98+S5K1YcMGy7Isa+zYsVaHDh2cPnPw4EFLkpWSkuLK2wKMEBsba/n6+lqBgYGOV69evaz27dtb48ePdzp29uzZVuXKlR0/S7JGjBjh+Dk5OdmSZL3zzjuOsblz51r+/v6XrOGaa66xXn31VcfP4eHh1qRJkyzLsqzvvvvOCg4OtrKyspw+U6NGDWvatGmFvl/AG/BVcPAoFSpUUKdOnTRjxgxZlqVOnTqpfPnyTsfs2rVLo0aN0po1a3T8+HFH8nfgwAFFRUXlO+emTZv07bffKigoKN97e/bsUe3atV1zM4BB2rVrpylTpjh+DgwM1LXXXqvvv//eKfHLzc1VVlaWzpw5o1KlSkmSrr32Wsf757/qqkGDBk5jWVlZysjIUHBwsDIzMzV69Gh98cUXOnLkiP744w+dPXv2ogngpk2blJmZqXLlyjmNnz179h+XjwDeigYQHqd///6O6Z7XX3893/tdunRReHi43nrrLVWpUkV5eXmKiopSTk7OBc+XmZmpLl266Pnnn8/3XuXKlYu2eMBQgYGBqlmzptNYZmamEhMT1aNHj3zH+/v7O/5csmRJx59tNttFx87/y96wYcO0ZMkSvfjii6pZs6YCAgLUq1evS/4zoHLlylq+fHm+90JDQwt2g4CXoQGEx7n55puVk5Mjm82mjh07Or134sQJpaSk6K233lKrVq0kSatWrbrk+aKjo/XJJ58oIiJCJUrwP3mguERHRyslJSVfY/hvff/994qLi1P37t0l/dng7d+//5J1pKamqkSJEoqIiCjSWoArFQ+BwOP4+vpq+/bt2rZtm3x9fZ3eK1OmjMqVK6c333xTu3fv1rJly5SQkHDJ8w0aNEgnT57UnXfeqZ9++kl79uzRokWLFB8fr9zcXFfeCmC0UaNGadasWUpMTNTWrVu1fft2ffDBBxoxYsS/Om+tWrU0b948bdy4UZs2bVLfvn0v+hCYJMXExKhZs2bq1q2bFi9erP3792v16tV6+umntXbt2n9VC3ClogGERwoODlZwcHC+cR8fH33wwQdat26doqKiNGTIEL3wwguXPFeVKlX0/fffKzc3Vx06dFCDBg00ePBghYaGyseHvwKAq3Ts2FELFy7U4sWL1aRJE91www2aNGmSwsPD/9V5J06cqDJlyqh58+bq0qWLOnbsqOjo6Iseb7PZ9OWXX6p169aKj49X7dq11adPH/3yyy+ONYeAaWyWZVnuLgIAAADFh/gDAADAMDSAAAAAhqEBBAAAMAwNIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AACAAAYhgYQgMeKi4tTt27dHD+3bdtWgwcPLvY6li9fLpvNpvT09GK/NgC4Ag0ggEKLi4uTzWaTzWaTn5+fatasqTFjxuiPP/5w6XXnzZunsWPHFuhYmjYAuLgS7i4AwJXp5ptv1vTp05Wdna0vv/xSgwYNUsmSJTV8+HCn43JycuTn51ck1yxbtmyRnAcATEcCCOCy2O12VapUSeHh4XrwwQcVExOjzz//3DFtO27cOFWpUkV16tSRJB08eFC9e/dWaGioypYtq65du2r//v2O8+Xm5iohIUGhoaEqV66cnnjiCf39q8r/PgWcnZ2tJ598UlWrVpXdblfNmjX1zjvvaP/+/WrXrp0kqUyZMrLZbIqLi5Mk5eXlKSkpSZGRkQoICNB1112n//3vf07X+fLLL1W7dm0FBASoXbt2TnUCgDegAQRQJAICApSTkyNJWrp0qVJSUrRkyRItXLhQ586dU8eOHVW6dGl99913+v777xUUFKSbb77Z8ZmXXnpJM2bM0LvvvqtVq1bp5MmT+vTTTy95zXvuuUdz587VK6+8ou3bt2vatGkKCgpS1apV9cknn0iSUlJSdOTIEb388suSpKSkJM2aNUtTp07V1q1bNWTIEPXr108rVqyQ9Gej2qNHD3Xp0kUbN27Uvffeq6eeespVvzYAcAumgAH8K5ZlaenSpVq0aJEeeeQRHTt2TIGBgXr77bcdU7/vvfee8vLy9Pbbb8tms0mSpk+frtDQUC1fvlwdOnTQ5MmTNXz4cPXo0UOSNHXqVC1atOii1925c6c++ugjLVmyRDExMZKk6tWrO94/P11csWJFhYaGSvozMRw/fry++eYbNWvWzPGZVatWadq0aWrTpo2mTJmiGjVq6KWXXpIk1alTR1u2bNHzzz9fhL81AHAvGkAAl2XhwoUKCgrSuXPnlJeXp759+2r06NEaNGiQGjRo4LTub9OmTdq9e7dKly7tdI6srCzt2bNHp06d0pEjR9S0aVPHeyVKlFDjxo3zTQOft3HjRvn6+qpNmzYFrnn37t06c+aMbrrpJqfxnJwcNWrUSJK0fft2pzokOZpFAPAWNIAALku7du00ZcoU+fn5qUqVKipR4v/+cRIYGOh0bGZmpq6//nq9//77+c5ToUKFy7p+QEBAoT+TmZkpSfriiy901VVXOb1nt9svqw4AuBLRAAK4LIGBgapZs2aBjo2OjtaHH36oihUrKjg4+ILHVK5cWWvWrFHr1q0lSX/88YfWrVun6OjoCx7foEED5eXlacWKFY4p4L86n0Dm5uY6xurXry+73a4DBw5cNDmsV6+ePv/8c6exH3744Z9vEgCuIDwEAsDl7rrrLpUvX15du3bVd999p3379mn58uV69NFH9euvv0qSHnvsMT333HOaP3++duzYoYceeuiSe/hFREQoNjZW/fv31/z58x3n/OijjyRJ4eHhstlsWrhwoY4dO6bMzEyVLl1aw4YN05AhQzRz5kzt2bNH69ev16uvvqqZM2dKkgYOHKhdu3bp8ccfV0pKiubMmaMZM2a4+lcEAMWKBhCAy5UqVUorV65UtWrV1KNHD9WrV08DBgxQVlaWIxEcOnSo7r77bsXGxqpZs2YqXbq0unfvfsnzTpkyRb169dJDDz2kunXr6r777tPp06clSVdddZUSExP11FNPKSwsTA8//LAkaezYsRo5cqSSkpJUr1493Xzzzfriiy8UGRkpSapWrZo++eQTzZ8/X9ddd52mTp2q8ePHu/C3AwDFz2ZdbIU1AAAAvBIJIAAAgGFoAAEAAAxDAwgAAGAYGkAAAADD0AACAAAYhgYQAADAMDSAAAAAhqEBBAAAMAwNIAAAgGFoAAEAAAxDAwgAAGCY/wdwrtdWt6R95QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.to(DEVICE)\n",
    "best_model.eval()\n",
    "test_loss = 0.0\n",
    "test_total = 0\n",
    "test_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        outputs = best_model(inputs)\n",
    "        te_loss = criterion(outputs, labels)\n",
    "        test_loss += te_loss.item()/inputs.size(0)\n",
    "        probability = torch.sigmoid(outputs)\n",
    "        predicted = (probability >= 0.5).float()\n",
    "        all_predicted.extend(predicted.cpu().numpy().ravel().tolist())\n",
    "        all_labels.extend(labels.cpu().numpy().ravel().tolist())\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}\")\n",
    "LOGGER.info(f\"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}\")\n",
    "accuracy = accuracy_score(all_labels, all_predicted)\n",
    "sensitivity = recall_score(all_labels, all_predicted)\n",
    "print(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')\n",
    "LOGGER.info(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predicted)\n",
    "print('CM: ',cm)\n",
    "LOGGER.info(f\"CM : {cm}\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation for Training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold [1/5], Epoch [1/10]: Train Loss: 1.1027 Train Accu: 65.11% Val Loss: 1.1186 Val Accu: 50.98%\n",
      "Fold [1/5], Epoch [2/10]: Train Loss: 1.0359 Train Accu: 69.29% Val Loss: 1.2397 Val Accu: 50.98%\n",
      "Fold [1/5], Epoch [3/10]: Train Loss: 0.9748 Train Accu: 69.04% Val Loss: 0.2247 Val Accu: 82.35%\n",
      "Fold [1/5], Epoch [4/10]: Train Loss: 0.9140 Train Accu: 76.90% Val Loss: 0.8988 Val Accu: 50.98%\n",
      "Fold [1/5], Epoch [5/10]: Train Loss: 0.8699 Train Accu: 76.41% Val Loss: 0.6120 Val Accu: 50.98%\n",
      "Fold [1/5], Epoch [6/10]: Train Loss: 0.7704 Train Accu: 83.05% Val Loss: 1.0548 Val Accu: 50.98%\n",
      "Fold [1/5], Epoch [7/10]: Train Loss: 0.8332 Train Accu: 77.89% Val Loss: 0.2202 Val Accu: 77.45%\n",
      "Fold [1/5], Epoch [8/10]: Train Loss: 0.7286 Train Accu: 84.77% Val Loss: 0.2578 Val Accu: 71.57%\n",
      "Fold [1/5], Epoch [9/10]: Train Loss: 0.7944 Train Accu: 80.84% Val Loss: 1.3172 Val Accu: 49.02%\n",
      "Fold [1/5], Epoch [10/10]: Train Loss: 0.7981 Train Accu: 79.85% Val Loss: 1.7724 Val Accu: 50.98%\n",
      "Fold 2/5\n",
      "Fold [2/5], Epoch [1/10]: Train Loss: 1.0929 Train Accu: 63.14% Val Loss: 1.0021 Val Accu: 52.94%\n",
      "Fold [2/5], Epoch [2/10]: Train Loss: 1.0073 Train Accu: 69.53% Val Loss: 1.2241 Val Accu: 52.94%\n",
      "Fold [2/5], Epoch [3/10]: Train Loss: 0.9256 Train Accu: 75.68% Val Loss: 1.0209 Val Accu: 52.94%\n",
      "Fold [2/5], Epoch [4/10]: Train Loss: 0.9505 Train Accu: 73.71% Val Loss: 0.9707 Val Accu: 47.06%\n",
      "Fold [2/5], Epoch [5/10]: Train Loss: 0.8162 Train Accu: 78.62% Val Loss: 0.9718 Val Accu: 52.94%\n",
      "Fold [2/5], Epoch [6/10]: Train Loss: 0.7941 Train Accu: 81.57% Val Loss: 0.5404 Val Accu: 57.84%\n",
      "Fold [2/5], Epoch [7/10]: Train Loss: 0.8598 Train Accu: 75.68% Val Loss: 0.3460 Val Accu: 60.78%\n",
      "Fold [2/5], Epoch [8/10]: Train Loss: 0.8215 Train Accu: 76.41% Val Loss: 0.1649 Val Accu: 92.16%\n",
      "Fold [2/5], Epoch [9/10]: Train Loss: 0.7269 Train Accu: 85.50% Val Loss: 0.2481 Val Accu: 73.53%\n",
      "Fold [2/5], Epoch [10/10]: Train Loss: 0.7155 Train Accu: 85.50% Val Loss: 0.1645 Val Accu: 95.10%\n",
      "Fold 3/5\n",
      "Fold [3/5], Epoch [1/10]: Train Loss: 1.1076 Train Accu: 64.62% Val Loss: 0.8082 Val Accu: 56.86%\n",
      "Fold [3/5], Epoch [2/10]: Train Loss: 1.0293 Train Accu: 71.74% Val Loss: 1.1901 Val Accu: 56.86%\n",
      "Fold [3/5], Epoch [3/10]: Train Loss: 0.9747 Train Accu: 73.22% Val Loss: 0.5200 Val Accu: 56.86%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     30\u001b[0m train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 32\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:317\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    171\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/anaconda3/envs/ninad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:214\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    212\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    213\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=NP_SEED)\n",
    "fold_train_losses, fold_val_losses = [], []\n",
    "fold_train_accuracies, fold_val_accuracies = [], []\n",
    "LOGGER.info(f\"{K_FOLDS} FOLDS CROSS VALIATION TARINING STARTED\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "    print(f'Fold {fold+1}/{K_FOLDS}')\n",
    "    LOGGER.info(f'Fold {fold+1}/{K_FOLDS}')\n",
    "    \n",
    "    train_ds = Subset(train_dataset, train_idx)\n",
    "    val_ds = Subset(train_dataset, val_idx)\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = SFCN().to(DEVICE)\n",
    "    model = nn.DataParallel(model) \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Train the model for each fold\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_total = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_dl:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            tloss = criterion(outputs, labels)\n",
    "            tloss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += tloss.item() / inputs.size(0)\n",
    "            probability = torch.sigmoid(outputs)\n",
    "            predicted = (probability >= 0.5).float()\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        fold_train_accuracies.append(train_accuracy)\n",
    "        fold_train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_total = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dl:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                vloss = criterion(outputs, labels)\n",
    "                val_loss += vloss.item() / inputs.size(0)\n",
    "                probability = torch.sigmoid(outputs)\n",
    "                predicted = (probability >= 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "            fold_val_accuracies.append(val_accuracy)\n",
    "            fold_val_losses.append(val_loss)\n",
    "\n",
    "            print(f\"Fold [{fold+1}/{K_FOLDS}], Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.2f}% Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.2f}%\")\n",
    "            LOGGER.info(f\"Fold [{fold+1}/{K_FOLDS}], Epoch [{epoch+1}/{NUM_EPOCHS}]: Train Loss: {train_loss:.4f} Train Accu: {train_accuracy:.2f}% Val Loss: {val_loss:.4f} Val Accu: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if epoch > 30:\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_without_improvement = 0 \n",
    "\n",
    "                new_state_dict = {}\n",
    "                for key, value in model.state_dict().items():\n",
    "                    new_key = key.replace(\"module.\", \"\")\n",
    "                    new_state_dict[new_key] = value\n",
    "                best_model.load_state_dict(new_state_dict)\n",
    "\n",
    "                # torch.save(model.state_dict(), f'{RESULT_DIR}/model_{fold+1}_epoch{epoch}.pt') # will create a lot of model and take a lot of space\n",
    "                LOGGER.info(f\"Validation loss improved for fold {fold+1} at epoch {epoch+1}\")\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                LOGGER.info(f\"No improvement in validation loss for {epochs_without_improvement} epochs for fold {fold+1}\")\n",
    "\n",
    "            if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
    "                print(f\"Early stopping triggered for fold {fold+1} at epoch {epoch+1}\")\n",
    "                LOGGER.info(f\"Early stopping triggered for fold {fold+1} at epoch {epoch+1}\")\n",
    "                ## save best model before stopping\n",
    "                torch.save(model.state_dict(), f'{RESULT_DIR}/best_model_{fold+1}_epoch{epoch}.pt')\n",
    "                break\n",
    "    \n",
    "    torch.save(model.state_dict(), f'{RESULT_DIR}/best_model_{fold+1}_epoch{epoch}.pt') ## save model as best model if the training ends for a fold\n",
    "\n",
    "# Aggregate the results across all folds\n",
    "avg_train_loss = np.mean(fold_train_losses)\n",
    "avg_val_loss = np.mean(fold_val_losses)\n",
    "avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "\n",
    "print(f\"Avg Train Loss: {avg_train_loss:.4f}, Avg Train Accu: {avg_train_accuracy:.2f}%, Avg Val Loss: {avg_val_loss:.4f}, Avg Val Accu: {avg_val_accuracy:.2f}%\")\n",
    "LOGGER.info(f\"Avg Train Loss: {avg_train_loss:.4f}, Avg Train Accu: {avg_train_accuracy:.2f}%, Avg Val Loss: {avg_val_loss:.4f}, Avg Val Accu: {avg_val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS: 14.311684928834438, TEST ACCURACY: 89.94082840236686\n",
      "Accuracy: 0.8994082840236687, Sensitivity (Recall): 0.9354838709677419\n",
      "CM:  [[65 11]\n",
      " [ 6 87]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = SFCN()\n",
    "\n",
    "best_model_state_dict = torch.load('/home/neelamlab/ninad/DWI/results/run_07_11_2024_16_27_35/best_model_2_epoch9.pt', weights_only=True)\n",
    "new_state_dict = {}\n",
    "for key, value in best_model_state_dict.items():\n",
    "    new_key = key.replace(\"module.\", \"\")\n",
    "    new_state_dict[new_key] = value\n",
    "best_model.load_state_dict(new_state_dict)\n",
    "\n",
    "best_model.to(DEVICE)\n",
    "best_model.eval()\n",
    "test_loss = 0.0\n",
    "test_total = 0\n",
    "test_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_predicted = []\n",
    "    all_labels = []\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        outputs = best_model(inputs)\n",
    "        te_loss = criterion(outputs, labels)\n",
    "        test_loss += te_loss.item()/inputs.size(0)\n",
    "        probability = torch.sigmoid(outputs)\n",
    "        predicted = (probability >= 0.5).float()\n",
    "        all_predicted.extend(predicted.cpu().numpy().ravel().tolist())\n",
    "        all_labels.extend(labels.cpu().numpy().ravel().tolist())\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}\")\n",
    "LOGGER.info(f\"TEST LOSS: {test_loss}, TEST ACCURACY: {test_accuracy}\")\n",
    "accuracy = accuracy_score(all_labels, all_predicted)\n",
    "sensitivity = recall_score(all_labels, all_predicted)\n",
    "print(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')\n",
    "LOGGER.info(f'Accuracy: {accuracy}, Sensitivity (Recall): {sensitivity}')\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predicted)\n",
    "print('CM: ',cm)\n",
    "LOGGER.info(f\"CM : {cm}\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",xticklabels=['Male', 'Female'], yticklabels=['Male', 'Female'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('cm.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ninad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
